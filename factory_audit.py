"""SoEasyHub v2 Factory Audit Script - One-time inspection"""
import os
import requests
import random

# Read from environment variables or use placeholders
SB_BASE = os.environ.get("SUPABASE_URL", "https://nbfzhxgkfljeuoncujum.supabase.co")
KEY = os.environ.get("SUPABASE_KEY", "MISSING_KEY_PLEASE_SET_ENV")
SB = f"{SB_BASE}/rest/v1/grich_keywords_pool"
H = {"apikey": KEY}

print("=" * 60)
print("  SoEasyHub v2 å·¥å‚æ—¥æŠ¥ - æ•°æ®èµ„äº§æ™®æŸ¥")
print("=" * 60)

# 1. Total
total = requests.get(SB + "?select=id", headers=H).json()
print(f"\nğŸ“¦ æ€»æ± å­ (å…³é”®è¯æ€»æ•°): {len(total)}")

# 2. Refined
refined = requests.get(SB + "?select=id&is_refined=eq.true", headers=H).json()
print(f"âš™ï¸  å·²ç²¾ç‚¼ (is_refined=true): {len(refined)}")

# 3. Has article
articles = requests.get(SB + "?select=slug,final_article&final_article=not.is.null&limit=200", headers=H).json()
print(f"ğŸ“ å·²å…¥åº“ (æœ‰ final_article): {len(articles)}")

over2k = [a for a in articles if a.get("final_article") and len(a["final_article"]) > 2000]
print(f"ğŸ’ ç²¾å“æ–‡ç«  (>2000å­—ç¬¦): {len(over2k)}")

# 4. PDF
pdfs = requests.get(SB + "?select=id&pdf_url=not.is.null", headers=H).json()
print(f"ğŸ“„ PDF è¦†ç›–ç‡: {len(pdfs)}")

# 5. Random 10 slugs for spot check
print("\n" + "=" * 60)
print("  æ­»é“¾æŠ½æ£€ - éšæœº 10 ç¯‡æ–‡ç« ")
print("=" * 60)

sample = random.sample(articles, min(10, len(articles)))
ok_count = 0
fail_count = 0

for s in sample:
    slug = s["slug"]
    url = f"https://www.soeasyhub.com/p/{slug}"
    try:
        resp = requests.get(url, timeout=15)
        html = resp.text
        has_29 = "$29.9" in html or "29.9" in html
        has_h1 = "<h1>" in html or "<h1 " in html
        has_h2 = "<h2>" in html or "<h2 " in html
        has_h3 = "<h3>" in html or "<h3 " in html
        has_md_hash = "\n### " in html or "\n## " in html or "\n# " in html
        
        status = "âœ…"
        issues = []
        if not has_29:
            issues.append("æ— $29.9æŒ‰é’®")
        if has_md_hash:
            issues.append("Markdownä¹±ç ")
        if not (has_h1 or has_h2 or has_h3):
            issues.append("æ— HTMLæ ‡é¢˜")
        
        if issues:
            status = "âš ï¸"
            fail_count += 1
        else:
            ok_count += 1
            
        issue_str = " | " + ", ".join(issues) if issues else ""
        alen = len(s.get("final_article", ""))
        print(f"  {status} {slug} | {alen}å­—ç¬¦ | HTTP {resp.status_code}{issue_str}")
    except Exception as e:
        fail_count += 1
        print(f"  âŒ {slug} | ERROR: {e}")

print(f"\næŠ½æ£€ç»“æœ: {ok_count}/10 é€šè¿‡, {fail_count}/10 æœ‰é—®é¢˜")

# 6. Sitemap check
print("\n" + "=" * 60)
print("  Sitemap å·¡æ£€")
print("=" * 60)
try:
    sitemap = requests.get("https://www.soeasyhub.com/sitemap.xml", timeout=15).text
    url_count = sitemap.count("<loc>")
    print(f"ğŸ—ºï¸  Sitemap URL æ€»æ•°: {url_count}")
    print(f"ğŸ“… lastmod: 2026-02-11")
except Exception as e:
    print(f"âŒ Sitemap è·å–å¤±è´¥: {e}")

print("\n" + "=" * 60)
print("  ä½“æ£€å®Œæ¯•")
print("=" * 60)
